import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
import io
from io import BytesIO


df_std = None
df_blank_processed = None
sample_tables = []
summary = None

st.title("–ë—Ä–∑–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞")

std_dataframes = []
df_blank_results = pd.DataFrame()
df_samples_results = pd.DataFrame()



# --- –ò–∑–±–æ—Ä –Ω–∞ –º–µ—Ç–æ–¥–∏ ---
st.markdown("### –ò–∑–±–µ—Ä–∏ –µ–¥–Ω–∞ –∏–ª–∏ –ø–æ–≤–µ—ú–µ –º–µ—Ç–æ–¥–∏ –∑–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞:")
method_one_point = st.checkbox("–ö–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –µ–¥–Ω–∞ —Ç–æ—á–∫–∞")
method_internal_curve = st.checkbox("–ö–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ –ø—Ä–∞–≤–∞ —Å–æ –≤–Ω–∞—Ç—Ä–µ—à–µ–Ω —Å—Ç–∞–Ω–¥–∞—Ä–¥")
method_external_curve = st.checkbox("–ö–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –Ω–∞–¥–≤–æ—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ –ø—Ä–∞–≤–∞")

# --- –ó–∞–µ–¥–Ω–∏—á–∫–∏ –ø–æ–ª–∏—ö–∞ ---
st.markdown("### –ü—Ä–æ–±–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑–∞")
blank_file = st.file_uploader("–ü—Ä–∏–∫–∞—á–∏ blank (.xlsx)", type=["xls", "xlsx"])
sample_files = st.file_uploader("–ü—Ä–∏–∫–∞—á–∏ samples (.xlsx)", type=["xls", "xlsx"], accept_multiple_files=True)
v_extract = st.number_input("–í–æ–ª—É–º–µ–Ω –Ω–∞ –∫–æ–Ω–µ—á–µ–Ω –µ–∫—Å—Ç—Ä–∞–∫—Ç (mL)", min_value=0.0, format="%.2f", key="v_extract")

# --- –∞–∫–æ –µ –ø–æ—Ç—Ä–µ–±–µ–Ω IS ---
if method_one_point or method_internal_curve:
    st.markdown("### –í–Ω–µ—Å–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –≤–Ω–∞—Ç—Ä–µ—à–µ–Ω —Å—Ç–∞–Ω–¥–∞—Ä–¥ ")
    is_name = st.text_input("–ò–º–µ –Ω–∞ –≤–Ω–∞—Ç—Ä–µ—à–µ–Ω —Å—Ç–∞–Ω–¥–∞—Ä–¥ (–∫–∞–∫–æ –≤–æ Excel)", key="is_name")

 # --- –ú–µ—Ç–æ–¥ 1: –ï–¥–Ω–∞ —Ç–æ—á–∫–∞ ---
if method_one_point:
    st.markdown("### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞ –º–µ—Ç–æ–¥–∞: –ö–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –µ–¥–Ω–∞ —Ç–æ—á–∫–∞")
    c_is_start = st.number_input("–ü–æ—á–µ—Ç–Ω–∞ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—ò–∞ –Ω–∞ IS (¬µg/L)", min_value=0.0, format="%.3f", key="c_is_start")

    st.markdown("#### –ü—Ä–∏–∫–∞—á–∏ —Å—Ç–∞–Ω–¥–∞—Ä–¥ –∑–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –µ–¥–Ω–∞ —Ç–æ—á–∫–∞:")
    std_file_one_point = st.file_uploader("–°—Ç–∞–Ω–¥–∞—Ä–¥ (1 –¥–æ–∫—É–º–µ–Ω—Ç)", type=["xls", "xlsx"], key="onep_file")
    conc_one_point = st.number_input("–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—ò–∞ –Ω–∞ –°—Ç–∞–Ω–¥–∞—Ä–¥–æ—Ç (¬µg/L)", min_value=0.0, format="%.3f", key="onep_conc")


        # --- –ú–µ—Ç–æ–¥ 2: –í–Ω–∞—Ç—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ –∫—Ä–∏–≤–∞ ---
if method_internal_curve:
    st.markdown("### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞ –º–µ—Ç–æ–¥–∞: –ö–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ –ø—Ä–∞–≤–∞ —Å–æ –≤–Ω–∞—Ç—Ä–µ—à–µ–Ω —Å—Ç–∞–Ω–¥–∞—Ä–¥")
    c_is_extract = st.number_input("–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—ò–∞ –Ω–∞ IS –≤–æ –µ–∫—Å—Ç—Ä–∞–∫—Ç (¬µg/L)", min_value=0.0, format="%.3f", key="c_is_extract")


      # --- –°–µ—Ä–∏—ò–∞ –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä–¥–∏ (–µ–¥–Ω–∞ –∑–∞ —Å–∏—Ç–µ –º–µ—Ç–æ–¥–∏ —à—Ç–æ —ò–∞ –∫–æ—Ä–∏—Å—Ç–∞—Ç) ---
if method_internal_curve or method_external_curve or (method_one_point and (method_internal_curve or method_external_curve)):
    st.markdown("### –°–µ—Ä–∏—ò–∞ –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä–¥–∏ –∑–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ –∫—Ä–∏–≤–∞")


    # –ë–∞—Ä–∞—ö–µ –±—Ä–æ—ò –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä–¥–∏ —Å–∞–º–æ –µ–¥–Ω–∞—à
    num_standards = st.number_input("–ö–æ–ª–∫—É —Å—Ç–∞–Ω–¥–∞—Ä–¥–∏ —ú–µ –∫–æ—Ä–∏—Å—Ç–∏—Ç–µ? –ê–∫–æ –∫–æ—Ä–∏—Å—Ç–∏—Ç–µ –º–µ—Ç–æ–¥–∞ –Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ –ø—Ä–∞–≤–∞ —Å–æ –≤–Ω–∞—Ç—Ä–µ—à–µ–Ω —Å—Ç–∞–Ω–¥–∞—Ä–¥ –ø—Ä–≤ —Å—Ç–∞–≤–µ—Ç–µ –≥–æ —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏–æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä–¥", min_value=1, max_value=20, value=5, step=1)

    uploaded_std_files = []
    std_concentrations = []
    std_dataframes = []

    # –ê–∫–æ –∫–æ—Ä–∏—Å–Ω–∏–∫–æ—Ç –∏–∑–±—Ä–∞–ª –±—Ä–æ—ò –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä–¥–∏ > 0, –ø—Ä–∏–∫–∞–∂–∏ –ø–æ–ª–µ—Ç–∞ –∑–∞ –≤–Ω–µ—Å
    if num_standards > 0:
        for i in range(num_standards):
            cols = st.columns(2)
            with cols[0]:
                file = st.file_uploader(f"–°—Ç–∞–Ω–¥–∞—Ä–¥ {i+1} ‚Äì Excel —Ñ–∞—ò–ª", type=["xls", "xlsx"], key=f"std_file_{i}")
                uploaded_std_files.append(file)
            with cols[1]:
                conc = st.number_input(f"–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—ò–∞ –∑–∞ —Å—Ç–∞–Ω–¥–∞—Ä–¥ {i+1} (¬µg/L)", min_value=0.0, format="%.4f", key=f"std_conc_{i}")
                std_concentrations.append(conc)


# --- –ö—Ä–∞—ò ---
st.markdown("---")
st.success("–í–Ω–µ—Å–∏ –≥–∏ —Å–∏—Ç–µ –ø–æ—Ç—Ä–µ–±–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ —Å–ø–æ—Ä–µ–¥ –∏–∑–±—Ä–∞–Ω–∏—Ç–µ –º–µ—Ç–æ–¥–∏.")


# PRVA METODA
if method_one_point:
    def find_column(df, possible_names):
        """–ù–∞–æ—ì–∞ –∫–æ–ª–æ–Ω–∞ –≤–æ df —Å–ø–æ—Ä–µ–¥ –ª–∏—Å—Ç–∞ –Ω–∞ –º–æ–∂–Ω–∏ –∏–º–∏—ö–∞."""
        for name in possible_names:
            if name in df.columns:
                return name
        return None

    if std_file_one_point is not None:
        # –ß–∏—Ç–∞—ö–µ –Ω–∞ Excel —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä–¥–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç
        df_std = pd.read_excel(std_file_one_point)

        # –ù–∞–æ—ì–∞—ö–µ –Ω–∞ –∫–æ–ª–æ–Ω–∏
        name_col = find_column(df_std, ["Name", "name", "NAME"])
        rt_col = find_column(df_std, ["RT","RT (min)", "Retention Time", "retention time", "rt"])
        height_col = find_column(df_std, ["Height", "Height (Hz)", "height", "height (Hz)"])

        if None in (name_col, rt_col, height_col):
            st.error("–ù–µ –º–æ–∂–∞–º –¥–∞ –≥–∏ –Ω–∞—ò–¥–∞–º –ø–æ—Ç—Ä–µ–±–Ω–∏—Ç–µ –∫–æ–ª–æ–Ω–∏ –≤–æ —Å—Ç–∞–Ω–¥–∞—Ä–¥–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç.")
        else:
            # –ë–∞—Ä–∞–º–µ –≤–∏—Å–∏–Ω–∞ –Ω–∞ IS
            is_mask = df_std[name_col].astype(str) == is_name
            if not is_mask.any():
                st.error(f"–í–Ω–∞—Ç—Ä–µ—à–Ω–∏–æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä–¥ '{is_name}' –Ω–µ –µ –ø—Ä–æ–Ω–∞—ò–¥–µ–Ω –≤–æ —Å—Ç–∞–Ω–¥–∞—Ä–¥–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç.")
            else:
                height_is = df_std.loc[is_mask, height_col].values[0]
                # –ü—Ä–µ—Å–º–µ—Ç–∫–∞ –Ω–∞ RRF
                df_std['RRF'] = df_std.apply(
                    lambda row: (row[height_col] / height_is) * (c_is_start / conc_one_point)
                    if row[name_col] != is_name else 1.0,
                    axis=1
                )

                # –°–æ–∑–¥–∞–≤–∞—ö–µ –Ω–∞ —Ä–µ–¥–µ–Ω –±—Ä–æ—ò
                df_std.insert(0, "–†–µ–¥. –±—Ä.", range(1, len(df_std) + 1))

                # –ü—Ä–æ–º–µ–Ω–∞ –Ω–∞ –∏–º–∏—ö–∞ –Ω–∞ –∫–æ–ª–æ–Ω–∏—Ç–µ –∑–∞ –ø–æ–¥–æ–±–∞—Ä –ø—Ä–∏–∫–∞–∑
                df_std = df_std.rename(columns={
                    name_col: "Name",
                    rt_col: "RT (min)",
                    height_col: "Height (Hz)"
                })

                st.markdown("### –¢–∞–±–µ–ª–∞ —Å–æ RRF:")
                st.dataframe(df_std[["–†–µ–¥. –±—Ä.", "Name", "RT (min)", "Height (Hz)", "RRF"]])

    def normalize_columns(df):
        # –ü—Ä–µ–ø–æ–∑–Ω–∞–≤–∞—ö–µ –Ω–∞ –∫–æ–ª–æ–Ω–∞ –∑–∞ Name
        name_cols = [col for col in df.columns if col.strip().lower() in ['name', 'compound']]

        # –ü—Ä–µ–ø–æ–∑–Ω–∞–≤–∞—ö–µ –Ω–∞ RT –∫–æ–ª–æ–Ω–∞
        rt_cols = [col for col in df.columns if any(x in col.lower() for x in ['rt (min)', 'rt'])]

        # –ü—Ä–µ–ø–æ–∑–Ω–∞–≤–∞—ö–µ –Ω–∞ Height –∫–æ–ª–æ–Ω–∞
        height_cols = [col for col in df.columns if 'height' in col.lower()]

        norm_df = pd.DataFrame()

        # –ò–∑–±–æ—Ä –Ω–∞ —Å–æ–æ–¥–≤–µ—Ç–Ω–∏ –∫–æ–ª–æ–Ω–∏, –∞–∫–æ —Å–µ –Ω–∞—ò–¥–µ–Ω–∏
        norm_df['Name'] = df[name_cols[0]] if name_cols else None
        norm_df['RT (min)'] = df[rt_cols[0]] if rt_cols else None
        norm_df['Height (Hz)'] = df[height_cols[0]] if height_cols else None

        return norm_df

    def process_sample(df_sample, df_std, c_is_start, v_extract, is_name):
        # –ù–∞–æ—ì–∞—ö–µ –Ω–∞ IS –≤–∏—Å–∏–Ω–∞ –≤–æ sample
        is_mask_sample = df_sample['Name'].astype(str) == is_name
        if not is_mask_sample.any():
            st.error(f"–í–Ω–∞—Ç—Ä–µ—à–Ω–∏–æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä–¥ '{is_name}' –Ω–µ –µ –ø—Ä–æ–Ω–∞—ò–¥–µ–Ω –≤–æ sample –¥–æ–∫—É–º–µ–Ω—Ç.")
            return None
        
        height_is_sample = df_sample.loc[is_mask_sample, 'Height (Hz)'].values[0]

        # –ì–µ–Ω–µ—Ä–∏—Ä–∞ —Ä–µ–¥–µ–Ω –±—Ä–æ—ò
        df_sample.insert(0, "–†–µ–¥. –±—Ä.", range(1, len(df_sample) + 1))

        # –ù–∞–æ—ì–∞—ö–µ RRF –æ–¥ —Å—Ç–∞–Ω–¥–∞—Ä–¥–∏ —Å–ø–æ—Ä–µ–¥ Name
        def get_rrf(name):
            match = df_std[df_std['Name'] == name]
            if not match.empty:
                return match['RRF'].values[0]
            else:
                return None

        df_sample['RRF'] = df_sample['Name'].apply(get_rrf)

        # –ü—Ä–µ—Å–º–µ—Ç–∫–∞ –Ω–∞ c(X)
        df_sample['c(X) / ¬µg L-1'] = df_sample.apply(lambda row: 
            (row['Height (Hz)'] / height_is_sample) * (c_is_start / row['RRF']) 
            if row['RRF'] else None, axis=1)

        # –ü—Ä–µ—Å–º–µ—Ç–∫–∞ –Ω–∞ –º–∞—Å–∞ –≤–æ ng
        df_sample['–ú–∞—Å–∞ (ng)'] = df_sample['c(X) / ¬µg L-1'] * v_extract

        return df_sample[['–†–µ–¥. –±—Ä.', 'Name', 'RT (min)', 'Height (Hz)', 'RRF', 'c(X) / ¬µg L-1', '–ú–∞—Å–∞ (ng)']]

       # --- –ü—Ä–∏–º–µ—Ä –∑–∞ blank –æ–±—Ä–∞–±–æ—Ç–∫–∞ ---
    if blank_file is not None:
        blank_df = pd.read_excel(blank_file)
        df_blank_processed = process_sample(blank_df, df_std, c_is_start, v_extract, is_name)
        if df_blank_processed is not None:
            st.markdown("### –ö–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –µ–¥–Ω–∞ —Ç–æ—á–∫–∞ - Blank:")
            st.dataframe(df_blank_processed)

    # --- –ü—Ä–∏–º–µ—Ä –∑–∞ samples –æ–±—Ä–∞–±–æ—Ç–∫–∞ ---
    sample_tables = []
    for idx, sample_file in enumerate(sample_files):
        sample_df = pd.read_excel(sample_file)
        df_sample_processed = process_sample(sample_df, df_std, c_is_start, v_extract, is_name)
        if df_sample_processed is not None:
            st.markdown(f"### –ö–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –µ–¥–Ω–∞ —Ç–æ—á–∫–∞ - Sample {idx + 1}:")
            st.dataframe(df_sample_processed)
            sample_tables.append(df_sample_processed)

    # --- –°—É–º–∞—Ä–Ω–∞ —Ç–∞–±–µ–ª–∞ —Å–æ —Å–∏—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—ò–∞ –∏ –º–∞—Å–∏ –≤–æ blank –∏ samples ---
    if df_blank_processed is not None and sample_tables:
        summary = df_blank_processed[['Name', '–ú–∞—Å–∞ (ng)']].rename(columns={'–ú–∞—Å–∞ (ng)': '–ú–∞—Å–∞ (ng) Blank'})
        for i, df_sample_proc in enumerate(sample_tables):
            summary = summary.merge(df_sample_proc[['Name', '–ú–∞—Å–∞ (ng)']].rename(columns={'–ú–∞—Å–∞ (ng)': f'–ú–∞—Å–∞ (ng) Sample {i + 1}'}),
                                    on='Name', how='outer')
        summary = summary.fillna(0)

        st.markdown("### –ö–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –µ–¥–Ω–∞ —Ç–æ—á–∫–∞ - —Å—É–º–∞—Ä–Ω–∞ —Ç–∞–±–µ–ª–∞:")
        st.dataframe(summary)

    if std_file_one_point is not None and df_std is not None:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # –¢–∞–±–µ–ª–∞ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä–¥–Ω–∏–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç
            df_std.to_excel(writer, sheet_name="RRFs", index=False)

            # Blank —Ç–∞–±–µ–ª–∞
            if df_blank_processed is not None:
                df_blank_processed.to_excel(writer, sheet_name="Blank", index=False)

            # Samples —Ç–∞–±–µ–ª–∏
            for i, df_sample_proc in enumerate(sample_tables):
                df_sample_proc.to_excel(writer, sheet_name=f"Sample {i + 1}", index=False)

            # –°—É–º–∏—Ä–∞–Ω–∞ —Ç–∞–±–µ–ª–∞
            if df_blank_processed is not None and sample_tables:
                summary.to_excel(writer, sheet_name="–°—É–º–∏—Ä–∞–Ω–æ", index=False)

        st.download_button(
            label="‚¨áÔ∏è –ü—Ä–µ–∑–µ–º–∏ –≥–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –≤–æ Excel - –ö–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –µ–¥–Ω–∞ —Ç–æ—á–∫–∞",
            data=output.getvalue(),
            file_name="kalibracija_edna_tocka.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )




#ako e vnesena serija standardi
if method_internal_curve or method_external_curve:
    for file in uploaded_std_files:
        if file is not None:
            df = pd.read_excel(file)
            std_dataframes.append(df)
def get_column_name(possible_names, columns):
    for name in possible_names:
        if name in columns:
            return name
    return None

if std_dataframes:
    df_reference = std_dataframes[0].copy()
    cols = df_reference.columns

    name_col = get_column_name(["Name", "name"], cols)
    rt_col = get_column_name(["RT (min)", "RT", "rt"], cols)
    height_col_base = get_column_name(["Height (Hz)", "Height", "height"], cols)

    if name_col and rt_col and height_col_base:
        result_df = df_reference[[name_col, rt_col]].copy()
        result_df.rename(columns={name_col: "Name", rt_col: "RT"}, inplace=True)

        for i, df_std in enumerate(std_dataframes):
            height_col = get_column_name(["Height (Hz)", "Height", "height"], df_std.columns)
            name_col_std = get_column_name(["Name", "name"], df_std.columns)

            if height_col and name_col_std:
                df_merge = df_std[[name_col_std, height_col]].copy()
                df_merge.rename(columns={
                    name_col_std: "Name",
                    height_col: f"Height_{i + 1}"
                }, inplace=True)

                result_df = result_df.merge(df_merge, on="Name", how="left")
            else:
                st.warning(f"‚ö†Ô∏è –°—Ç–∞–Ω–¥–∞—Ä–¥ {i + 1} –Ω–µ–º–∞ 'Name' –∏/–∏–ª–∏ 'Height' –∫–æ–ª–æ–Ω–∏.")

        st.write("### –°–æ–±—Ä–∞–Ω–∏ –≤–∏—Å–∏–Ω–∏ –æ–¥ —Å–∏—Ç–µ —Å—Ç–∞–Ω–¥–∞—Ä–¥–∏:")
        st.dataframe(result_df)
    else:
            st.warning("‚õî –ü—Ä–≤–∏–æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä–¥ –º–æ—Ä–∞ –¥–∞ –≥–∏ —Å–æ–¥—Ä–∂–∏ –∫–æ–ª–æ–Ω–∏—Ç–µ: Name –∏–ª–∏ name, Height (Hz), height, –∏–ª–∏ Height –∏ RT –∏–ª–∏ RT(min)")

#EKSTERNA KALIBRACIJA
if method_external_curve and 'result_df' in locals() and result_df is not None and std_concentrations:
    calibration_data = []

    X_full = np.array(std_concentrations).reshape(-1, 1)

    df_blank_processed = None
    if blank_file is not None:
        df_blank_processed = pd.read_excel(blank_file)

    sample_tables = []
    if sample_files:
        for f in sample_files:
            sample_tables.append(pd.read_excel(f))






        # –§–∏–ª—Ç—Ä–∏—Ä–∞—ö–µ –Ω–∞ –∫–æ–ª–æ–Ω–∏—Ç–µ —à—Ç–æ —Å–µ —Å–∞–º–æ Height_X
        height_columns = [col for col in result_df.columns if col.startswith("Height_")]

        for index, row in result_df.iterrows():
            name = row["Name"]
            heights = row[height_columns].values

            # –ö–æ–º–±–∏–Ω–∏—Ä–∞—ò –≥–∏ —Å–∞–º–æ –≤–∞–ª–∏–¥–Ω–∏—Ç–µ –ø–∞—Ä–æ–≤–∏
            valid_pairs = [(x, y) for x, y in zip(std_concentrations, heights) if pd.notna(y)]

            if len(valid_pairs) < 2:
                continue

            x_vals, y_vals = zip(*valid_pairs)
            X = np.array(x_vals).reshape(-1, 1)
            y = np.array(y_vals).reshape(-1, 1)

            model = LinearRegression()
            model.fit(X, y)

            slope = float(model.coef_)
            intercept = float(model.intercept_)
            r2 = float(model.score(X, y))

            calibration_data.append({
                "Name": name,
                "Slope": slope,
                "Intercept": intercept,
                "Correlation (R¬≤)": r2
            })

        df_calibration = pd.DataFrame(calibration_data)

        if not df_calibration.empty:
            st.write("### –ö–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ –ø—Ä–∞–≤–∞ –∑–∞ –Ω–∞–¥–≤–æ—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞:")
            st.dataframe(df_calibration)
        else:
            st.warning("‚ö†Ô∏è –ù–µ–º–∞ –¥–æ–≤–æ–ª–Ω–æ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –¥–∞ —Å–µ –∏–∑–≤—Ä—à–∏ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞.")

    else:
        st.warning("–ù–µ–º–∞ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä–¥–Ω–∏ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏ –∑–∞ –∫–∞–ª–∫—É–ª–∞—Ü–∏—ò–∞.")



    def calculate_concentration_and_mass(df, df_calib, v_extract):
        df_result = df.copy()
        df_result["c(X) / ¬µg/L"] = None
        df_result["–ú–∞—Å–∞ (ng)"] = None

        for idx, row in df_result.iterrows():
            name = row.get("Name")
            height = row.get("Height") or row.get("Height (Hz)") or row.get("height")

            if pd.isna(height):
                continue

            calib_row = df_calib[df_calib["Name"] == name]
            if not calib_row.empty:
                slope = calib_row["Slope"].values[0]
                intercept = calib_row["Intercept"].values[0]

                if slope != 0:
                    conc = (height - intercept) / slope
                    mass = conc * v_extract

                    df_result.at[idx, "c(X) / ¬µg/L"] = conc
                    df_result.at[idx, "–ú–∞—Å–∞ (ng)"] = mass

        return df_result


    # –ü—Ä–µ—Å–º–µ—Ç–∫–∞ –∑–∞ blank
    blank_final = None
    if df_blank_processed is not None and not df_calibration.empty:
        blank_final = calculate_concentration_and_mass(df_blank_processed, df_calibration, v_extract)
        st.markdown("### –ù–∞–¥–≤–æ—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ - Blank:")
        st.dataframe(blank_final)

    # –ü—Ä–µ—Å–º–µ—Ç–∫–∞ –∑–∞ samples
    samples_final = []
    if sample_tables and not df_calibration.empty:
        for df_sample in sample_tables:
            sample_calc = calculate_concentration_and_mass(df_sample, df_calibration, v_extract)
            samples_final.append(sample_calc)
            st.markdown(f"### –ù–∞–¥–≤–æ—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ - Sample {len(samples_final)} :")
            st.dataframe(sample_calc)

    # –°—É–º–∏—Ä–∞–Ω–∞ —Ç–∞–±–µ–ª–∞
    if blank_final is not None and samples_final:
        all_names = set(blank_final["Name"].unique())
        for df_s in samples_final:
            all_names.update(df_s["Name"].unique())

        summary_data = []
        for name in all_names:
            row = {"Name": name}
            blank_mass = blank_final[blank_final["Name"] == name]["–ú–∞—Å–∞ (ng)"].sum()
            row["Blank"] = blank_mass
            for i, df_s in enumerate(samples_final):
                sample_mass = df_s[df_s["Name"] == name]["–ú–∞—Å–∞ (ng)"].sum()
                row[f"Sample {i + 1}"] = sample_mass
            summary_data.append(row)

        df_summary = pd.DataFrame(summary_data)

        st.markdown("### –ù–∞–¥–≤–æ—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ - —Å—É–º–∏—Ä–∞–Ω–æ:")
        st.dataframe(df_summary)

        # –ì–µ–Ω–µ—Ä–∏—Ä–∞—ö–µ Excel —Å–æ —Å–∏—Ç–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            blank_final.to_excel(writer, sheet_name="Blank", index=False)
            for i, df_s in enumerate(samples_final):
                df_s.to_excel(writer, sheet_name=f"Sample {i + 1}", index=False)
            df_summary.to_excel(writer, sheet_name="–°—É–º–∏—Ä–∞–Ω–æ", index=False)
        output.seek(0)

        st.download_button(
            label="‚¨áÔ∏è –°–∏–º–Ω–∏ –≥–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –≤–æ –µ–∫—Å–µ–ª - –Ω–∞–¥–≤–æ—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞",
            data=output,
            file_name="nadvoresna_kalibraciona.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.warning("–ù–µ –º–æ–∂–µ –¥–∞ —Å–µ –≥–µ–Ω–µ—Ä–∏—Ä–∞ —Å—É–º–∞—Ä–Ω–∞ —Ç–∞–±–µ–ª–∞ –ø–æ—Ä–∞–¥–∏ –Ω–µ–¥–æ—Å—Ç–∞—Å—É–≤–∞—á–∫–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞ blank –∏–ª–∏ samples.")



# INTERNA
# –û—Å–∏–≥—É—Ä–∞—ò —Å–µ –¥–µ–∫–∞ result_df –∏ std_concentrations —Å–µ –¥–µ—Ñ–∏–Ω–∏—Ä–∞–Ω–∏
if 'result_df' not in locals():
    result_df = None
if 'std_concentrations' not in locals():
    std_concentrations = []

# –í–Ω–∞—Ç—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—ò–∞ —Å–æ –∫—Ä–∏–≤–∞ - –∏–∑–≤—Ä—à—É–≤–∞—ö–µ —Å–∞–º–æ –∞–∫–æ —Å–µ –≤–∫–ª—É—á–∏ –æ–≤–∞–∞ –æ–ø—Ü–∏—ò–∞
if method_internal_curve and result_df is not None and std_concentrations:

    # 1. –ü—Ä–µ—Å–º–µ—Ç–∞—ò C(X)/C(IS) —Ä–µ–≥—Ä–µ—Å–∏—ò–∞ –±–∞–∑–∏—Ä–∞–Ω–∞ –Ω–∞ H(X)/H(IS)
    std_conc_norm = np.array(std_concentrations) / std_concentrations[0]
    std_conc_norm = std_conc_norm.reshape(-1, 1)

    # –ü–æ–¥–≥–æ—Ç–≤–∏ ratio_df = H(X)/H(IS) –∑–∞ —Å–µ–∫–æ—ò —Å—Ç–∞–Ω–¥–∞—Ä–¥
    ratio_df = result_df[["Name"]].copy()
    height_cols = [col for col in result_df.columns if col.startswith("Height_")]

    for idx, col in enumerate(height_cols):
        df_std = std_dataframes[idx]  # –∑–µ–º–∏ –≥–æ —Å–æ–æ–¥–≤–µ—Ç–Ω–∏–æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä–¥
        is_row = df_std[df_std[name_col] == is_name]

        if not is_row.empty:
            is_height = is_row[height_col_base].values[0]
            if pd.notna(is_height) and is_height != 0:
                ratio_df[f"Ratio_{col.split('_')[-1]}"] = result_df[col] / is_height
            else:
                st.warning(f"‚ö†Ô∏è –í–∏—Å–∏–Ω–∞—Ç–∞ –∑–∞ IS ({is_name}) –≤–æ —Å—Ç–∞–Ω–¥–∞—Ä–¥ {idx+1} –Ω–µ –µ –≤–∞–ª–∏–¥–Ω–∞: {is_height}")
                ratio_df[f"Ratio_{col.split('_')[-1]}"] = np.nan
        else:
            st.warning(f"‚ö†Ô∏è IS '{is_name}' –Ω–µ –µ –ø—Ä–æ–Ω–∞—ò–¥–µ–Ω –≤–æ —Å—Ç–∞–Ω–¥–∞—Ä–¥ {idx+1}.")
            ratio_df[f"Ratio_{col.split('_')[-1]}"] = np.nan

    # –ê–∫–æ —É—Å–ø–µ—à–Ω–æ —Å–µ –ø—Ä–µ—Å–º–µ—Ç–∞–Ω–∏ –æ–¥–Ω–æ—Å–∏—Ç–µ, –ø—Ä–æ–¥–æ–ª–∂–∏ —Å–æ —Ä–µ–≥—Ä–µ—Å–∏—ò–∞
    if ratio_df is not None:
        regression_results = []

        for idx, row in ratio_df.iterrows():
            name = row["Name"]
            ratios = [row.get(f"Ratio_{i+1}", np.nan) for i in range(len(std_concentrations))]

            if pd.isna(ratios).any():
                continue

            y_vals = np.array(ratios).reshape(-1, 1)
            model = LinearRegression()
            model.fit(std_conc_norm, y_vals)

            slope = float(model.coef_)
            intercept = float(model.intercept_)
            correl = float(np.corrcoef(std_conc_norm.flatten(), y_vals.flatten())[0, 1])

            regression_results.append({
                "Name": name,
                "H(X)/H(IS)": "; ".join([f"{r:.3f}" for r in ratios]),
                "c(X)/c(IS)": f"{slope:.6f}",
                "Intercept": f"{intercept:.6f}",
                "Correlation": f"{correl:.4f}"
            })

        df_c_over_cis = pd.DataFrame(regression_results)
        st.write("df_c_over_cis preview:", df_c_over_cis.head())

        st.markdown("### –í–Ω–∞—Ç—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ –ø—Ä–∞–≤–∞")
        st.dataframe(df_c_over_cis)

        # 2. –ü—Ä–∏–º–µ–Ω–∏ –≥–∏ —Ä–µ–≥—Ä–µ—Å–∏–∏—Ç–µ –Ω–∞ –±–ª–∞–Ω–∫–æ–≤–∏ –∏ —Å–µ–º–ø–ª–æ–≤–∏
        all_samples = []

        if blank_file is not None:
            df_blank = pd.read_excel(blank_file)
            df_blank["Sample ID"] = "Blank"
            all_samples.append(df_blank)

        if sample_files:
            for idx, f in enumerate(sample_files):
                df_sample = pd.read_excel(f)
                df_sample["Sample ID"] = f"Sample_{idx+1}"
                all_samples.append(df_sample)

        df_all_samples = pd.concat(all_samples, ignore_index=True)

        blank_results = []
        samples_results = []

        for sample_id in df_all_samples["Sample ID"].unique():
            df_current = df_all_samples[df_all_samples["Sample ID"] == sample_id]
            is_row = df_current[df_current[name_col] == is_name]

            if is_row.empty:
                st.warning(f"‚ö†Ô∏è IS '{is_name}' –Ω–µ –µ –ø—Ä–æ–Ω–∞—ò–¥–µ–Ω –≤–æ {sample_id}.")
                continue

            is_height_sample = is_row[height_col_base].values[0]
            if pd.isna(is_height_sample) or is_height_sample == 0:
                st.warning(f"‚ö†Ô∏è –í–∏—Å–∏–Ω–∞—Ç–∞ –∑–∞ IS –≤–æ {sample_id} –Ω–µ –µ –≤–∞–ª–∏–¥–Ω–∞.")
                continue

            for _, analyte_row in df_current.iterrows():
                compound_name = analyte_row[name_col]
                if compound_name == is_name:
                    continue

                analyte_height = analyte_row[height_col_base]
                if pd.isna(analyte_height):
                    continue

                hx_over_his = analyte_height / is_height_sample
                row_reg = df_c_over_cis[df_c_over_cis["Name"] == compound_name]

                if row_reg.empty:
                    continue

                slope = float(row_reg["c(X)/c(IS)"].values[0])
                intercept = float(row_reg["Intercept"].values[0])

                cx_over_cis = (hx_over_his - intercept) / slope
                cx = cx_over_cis * c_is_extract
                final_amt = cx * v_extract

                row_result = {
                    "Name": compound_name,
                    "H(X)/H(IS)": hx_over_his,
                    "C(X)/C(IS)": cx_over_cis,
                    "C(X)": cx,
                    "–ú–∞—Å–∞ (ng)": final_amt
                }

                if sample_id == "Blank":
                    blank_results.append(row_result)
                else:
                    row_result["Sample ID"] = sample_id
                    samples_results.append(row_result)

        df_blank_results = pd.DataFrame(blank_results)
        df_samples_results = pd.DataFrame(samples_results)

        if df_blank_results.empty or df_samples_results.empty:
            st.warning("DataFrames —Å–µ –ø—Ä–∞–∑–Ω–∏, –ø—Ä–æ–≤–µ—Ä–µ—Ç–µ –≤–ª–µ–∑–Ω–∏—Ç–µ –ø–æ–¥–∞—Ç–æ—Ü–∏.")
    
        st.markdown("### –í–Ω–∞—Ç—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ - Blank")
        st.dataframe(df_blank_results)

        st.markdown("### –í–Ω–∞—Ç—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ - Samples")
        st.dataframe(df_samples_results)

        # –°—É–º–∏—Ä–∞–Ω–∞ —Ç–∞–±–µ–ª–∞: —Å–µ–∫–æ—ò sample –ø–æ—Å–µ–±–Ω–∞ –∫–æ–ª–æ–Ω–∞
        # –ó–∞—à—Ç–∏—Ç–∞ –æ–¥ –ø—Ä–∞–∑–Ω–∏ –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω–∏ DataFrame-–∏
        if df_blank_results.empty or df_samples_results.empty:
            st.warning("Blank –∏–ª–∏ Sample —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ —Å–µ –ø—Ä–∞–∑–Ω–∏ - –ø—Ä–∏–∫–∞—á–∏ —Ñ–∞—ò–ª–æ–≤–∏.")
        else:
            if "Name" in df_blank_results.columns and "Name" in df_samples_results.columns:
                all_names = set(df_blank_results["Name"].unique()) | set(df_samples_results["Name"].unique())
                sample_ids = df_samples_results["Sample ID"].unique()

                summary_rows = []

                for name in sorted(all_names):
                    row = {"Name": name}

                    # Blank
                    blank_mass = df_blank_results[df_blank_results["Name"] == name]["–ú–∞—Å–∞ (ng)"].sum()
                    row["Blank"] = blank_mass

                    # –°–µ–∫–æ—ò sample
                    for sid in sample_ids:
                        val = df_samples_results[
                            (df_samples_results["Name"] == name) & 
                            (df_samples_results["Sample ID"] == sid)
                        ]["–ú–∞—Å–∞ (ng)"].sum()
                        row[sid] = val

                    summary_rows.append(row)

                df_summary = pd.DataFrame(summary_rows)

                st.markdown("### –í–Ω–∞—Ç—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞ - —Å—É–º–∏—Ä–∞–Ω–æ")
                st.dataframe(df_summary)

                # –ì–µ–Ω–µ—Ä–∏—Ä–∞—ò Excel
                output_excel = io.BytesIO()
                with pd.ExcelWriter(output_excel, engine="openpyxl") as writer:
                    df_blank_results.to_excel(writer, sheet_name="Blank", index=False)
                    df_samples_results.to_excel(writer, sheet_name="Samples", index=False)
                    df_summary.to_excel(writer, sheet_name="Summary", index=False)
                output_excel.seek(0)

                st.download_button(
                    label="üíæ –°–∏–º–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ - –≤–Ω–∞—Ç—Ä–µ—à–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–∞",
                    data=output_excel.getvalue(),
                    file_name="vnatresna_kalibraciona.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Å—É–≤–∞ –∫–æ–ª–æ–Ω–∞—Ç–∞ 'Name' –≤–æ –Ω–µ–∫–æ—ò –æ–¥ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ.")
                



#krajna tabela
# --- –ë–µ–∑–±–µ–¥–Ω–æ –∑–µ–º–∞—ö–µ –∏–º–∏—ö–∞ –æ–¥ —Å—Ç–∞–Ω–¥–∞—Ä–¥ ---
std_names = []

if method_one_point and not (method_internal_curve or method_external_curve):
    if 'df_std' in locals() and isinstance(df_std, pd.DataFrame) and 'Name' in df_std.columns:
        df_std['Name'] = df_std['Name'].astype(str).str.strip().str.lower()
        std_names = df_std['Name'].dropna().unique().tolist()
else:
    combined_std_df = pd.concat(std_dataframes, ignore_index=True) if std_dataframes else pd.DataFrame()
    if not combined_std_df.empty and 'Name' in combined_std_df.columns:
        combined_std_df['Name'] = combined_std_df['Name'].astype(str).str.strip().str.lower()
        std_names = combined_std_df['Name'].dropna().unique().tolist()



# --- –ü–æ—á–µ—Ç–Ω–∞ —Ç–∞–±–µ–ª–∞ —Å–∞–º–æ —Å–æ –∏–º–∏—ö–∞—Ç–∞ –æ–¥ —Å—Ç–∞–Ω–¥–∞—Ä–¥–æ—Ç ---
df_combined = pd.DataFrame({'Name': sorted(std_names)})

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ —Ç–∞–±–µ–ª–∏—Ç–µ –æ–¥ –º–µ—Ç–æ–¥–∏—Ç–µ ---
dfs_to_merge = []

def normalize_name_column(df):
    df = df.copy()
    if 'Name' in df.columns:
        df['Name'] = df['Name'].astype(str).str.strip().str.lower()
    return df

# One Point Method
summary = locals().get('summary')
if isinstance(summary, pd.DataFrame) and not summary.empty:
    df_1p = normalize_name_column(summary)
    df_1p = df_1p.rename(columns=lambda c: f"{c} (One Point)" if c != 'Name' else c)
    dfs_to_merge.append(df_1p)

# Internal Curve
df_summary = locals().get('df_summary')
if isinstance(df_summary, pd.DataFrame) and not df_summary.empty:
    df_internal = normalize_name_column(df_summary)
    df_internal = df_internal.rename(columns=lambda c: f"{c} (Internal Curve)" if c != 'Name' else c)
    dfs_to_merge.append(df_internal)

# External Curve
df_summary_external = locals().get('df_summary_external')
if isinstance(df_summary_external, pd.DataFrame) and not df_summary_external.empty:
    df_external = normalize_name_column(df_summary_external)
    df_external = df_external.rename(columns=lambda c: f"{c} (External Curve)" if c != 'Name' else c)
    dfs_to_merge.append(df_external)

# --- –°–ø–æ—ò—É–≤–∞—ö–µ —Å–∞–º–æ —Å–ø–æ—Ä–µ–¥ —Å—Ç–∞–Ω–¥–∞—Ä–¥–Ω–∏—Ç–µ –∏–º–∏—ö–∞ ---
for df_method in dfs_to_merge:
    df_combined = df_combined.merge(df_method, on='Name', how='left')

# --- –ü–æ–ø–æ–ª–Ω—É–≤–∞—ö–µ –ø—Ä–∞–∑–Ω–∏ –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏ —Å–æ 0 ---
df_combined = df_combined.fillna(0)

# --- –ü—Ä–∏–∫–∞–∂–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç ---
st.markdown("### –ö–æ–º–±–∏–Ω–∏—Ä–∞–Ω–∞ —Å—É–º–∏—Ä–∞–Ω–∞ —Ç–∞–±–µ–ª–∞ –∑–∞ —Å–∏—Ç–µ –º–µ—Ç–æ–¥–∏ –∏ samples:")
st.dataframe(df_combined)




#odzemanja
import re

# --- –ü–æ–º–æ—à–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞: –Ω–æ—Ä–º–∞–ª–∏–∑–∏—Ä–∞—ö–µ ---
def normalize(df, method_label):
    df = df.copy()
    df['Name'] = df['Name'].astype(str).str.strip().str.lower()
    df = df.rename(columns={col: f"{col} ({method_label})" for col in df.columns if col != 'Name'})
    return df

# --- –ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞: –∫–æ—Ä–µ–∫—Ü–∏—ò–∞ –ø–æ –º–µ—Ç–æ–¥ —Å–æ —Å–æ–ø—Å—Ç–≤–µ–Ω blank ---
def correct_by_individual_blank(df_method, method_label):
    df_method = normalize(df_method, method_label)
    val_col = [col for col in df_method.columns if col != 'Name'][0]

    corrected_rows = []

    for idx, row in df_method.iterrows():
        name = row['Name']
        
        # Skip blank rows
        if re.search(r'\b(blank|—Å–ª–µ–ø–∞)\b', name, flags=re.IGNORECASE):
            continue

        # Tentaive blank name (tries to match with corresponding blank)
        possible_blank_names = [
            f"blank {name}", f"—Å–ª–µ–ø–∞ {name}", f"{name} blank", f"{name} —Å–ª–µ–ø–∞"
        ]

        blank_row = df_method[df_method['Name'].isin(possible_blank_names)]

        if not blank_row.empty:
            blank_val = blank_row.iloc[0][val_col]
        else:
            blank_val = 0  # –∞–∫–æ –Ω–µ–º–∞ blank –∑–∞ –æ–≤–æ—ò sample

        corrected_val = row[val_col] - blank_val

        corrected_rows.append({'Name': name, f"{val_col} (corrected)": corrected_val})

    return pd.DataFrame(corrected_rows)

# --- –°–æ–±–µ—Ä–∏ –≥–∏ —Å–∏—Ç–µ –º–µ—Ç–æ–¥–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∏ –≥–∏ –æ–¥–¥–µ–ª–Ω–æ ---
final_tables = []

if isinstance(summary, pd.DataFrame) and not summary.empty:
    corrected_1p = correct_by_individual_blank(summary, "One Point")
    final_tables.append(corrected_1p)

if isinstance(df_summary, pd.DataFrame) and not df_summary.empty:
    corrected_internal = correct_by_individual_blank(df_summary, "Internal Curve")
    final_tables.append(corrected_internal)

if isinstance(df_summary_external, pd.DataFrame) and not df_summary_external.empty:
    corrected_external = correct_by_individual_blank(df_summary_external, "External Curve")
    final_tables.append(corrected_external)

# --- –°–ø–æ—ò—É–≤–∞—ö–µ –Ω–∞ —Å–∏—Ç–µ –≤–æ –µ–¥–Ω–∞ —Ç–∞–±–µ–ª–∞ –ø–æ Name ---
from functools import reduce
df_final = reduce(lambda left, right: pd.merge(left, right, on='Name', how='outer'), final_tables)

# --- –°–æ—Ä—Ç–∏—Ä–∞—ö–µ –∏ –ø–æ–ø–æ–ª–Ω—É–≤–∞—ö–µ –ø—Ä–∞–∑–Ω–∏ –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏ ---
df_final = df_final.fillna(0)
df_final = df_final.sort_values('Name').reset_index(drop=True)

# --- –ü—Ä–∏–∫–∞–∑ ---
st.markdown("### –§–∏–Ω–∞–ª–Ω–∞ –∫–æ–º–ø–∞—Ä–∞—Ç–∏–≤–Ω–∞ —Ç–∞–±–µ–ª–∞ —Å–æ –æ–¥–∑–µ–º–µ–Ω–∏ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–Ω–∏ —Å–ª–µ–ø–∏ –ø—Ä–æ–±–∏:")
st.dataframe(df_final)
